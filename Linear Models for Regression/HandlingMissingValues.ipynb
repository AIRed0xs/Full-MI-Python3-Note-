{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11233/3055193395.py:35: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  correlation = train_data.corr()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import urllib.request \n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "\n",
    "data_path = 'https://raw.githubusercontent.com/nyandwi/public_datasets/master/housing.csv'\n",
    "\n",
    "def download_read_data(path):\n",
    "    \n",
    "    \"\"\"\n",
    "     Function to retrieve data from the data paths\n",
    "     And to read the data as a pandas dataframe\n",
    "  \n",
    "    To return the dataframe\n",
    "    \"\"\" \n",
    "    \n",
    "      ## Only retrieve the directory of the data\n",
    "\n",
    "    data_path =  urllib.request.urlretrieve(path)[0]\n",
    "    data = pd.read_csv(path)\n",
    "    \n",
    "    return data\n",
    "\n",
    "cal_data = download_read_data(data_path)\n",
    "train_data, test_data = train_test_split(cal_data, test_size=0.1,random_state=20)\n",
    "cal_train = train_data.copy()\n",
    "correlation = train_data.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing values are inevitable in real world datasets, so it's good to know how to handle them.\n",
    "#There are three options when dealing with missing values. You can:\n",
    "\n",
    "   # Remove them completely\n",
    "   # Fill them with different strategies such as mean, median, frequent, or constant.\n",
    "   # Leave them as they are. Most ML models don't appreciate missing values, and so they can't handle them but there are some models which are not affected by missing values, such as tree based algorithms. Since we are working with linear models for now, this is not an option.\n",
    "#Sklearn provides a function called SimpleImputer to fill missing values\n",
    "from matplotlib.pyplot import axis\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "training_input_data = train_data.drop('median_house_value', axis=1)\n",
    "training_labels = train_data['median_house_value']\n",
    "#We are going to impute all numerical features\n",
    "#Ideally, we would only impute bed_rooms becuase its the one possessing NaNs\n",
    "num_feats = training_input_data.drop('ocean_proximity', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude             0\n",
       "latitude              0\n",
       "housing_median_age    0\n",
       "total_rooms           0\n",
       "total_bedrooms        0\n",
       "population            0\n",
       "households            0\n",
       "median_income         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def handle_missing_values(input_data):\n",
    "  \"\"\"\n",
    "  Docstring \n",
    "\n",
    "  # This is a function to take numerical features...\n",
    "  ...and impute the missing values\n",
    "  # We are filling missing values with mean\n",
    "  # fit_transform fit the imputer on input data and transform it immediately\n",
    "  # You can use fit(input_data) and then transform(input_data) or\n",
    "  # Or do it at once with fit.transform(input_data)\n",
    "  # Imputer returns the imputed data as a NumPy array \n",
    "  # We will convert it back to Pandas dataframe\n",
    "\n",
    "  \"\"\"\n",
    "  mean_imputer = SimpleImputer(strategy='mean')\n",
    "  num_feats_imputed = mean_imputer.fit_transform(input_data)\n",
    "  num_feats_imputed = pd.DataFrame(num_feats_imputed, \n",
    "                            columns=input_data.columns, index=input_data.index )\n",
    "\n",
    "\n",
    "  return num_feats_imputed\n",
    "num_feats_imputed = handle_missing_values(num_feats)\n",
    "num_feats_imputed.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The feature total_bedroom was the one having missing values. Looking above, we no longer have the missing values in whole dataframe."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
