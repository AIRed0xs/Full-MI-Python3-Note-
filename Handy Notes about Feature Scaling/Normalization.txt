Normalization is a scaling techniques that transform the numerical feature to the range of values between 0 and 1.

Here is a formula that is followed when normalizing the data. Xmin
is the minimum value of feature X, and Xmax

is the maximum value of X.
   Xnorm= X−Xmin/Xmax−Xmin


When Should you Normalize the Features?

When you have features that have different ranges of values, normalizing these features can be a good practice.

Take an example. If you have two features that have different ranges (say one feature from 1-100, other vary from 5-300), you will to scale them so they have the same range of values.

More specifically, normalization is a preferrable scaling technique when the data at hand has not a normal or gaussian distribution. If the data's distribution is gaussian, standardization is a preferrable scaling technique. If you don't know the distribution of the data, still, normalization is a good choice at first.

With that said, when the ML algorithm of choice is either neural network or K-Nearest Neighbors(KNN), normalization is a good choice for these type of algorithms because they don't make any assumption of the input data.

Most popular ML frameworks provide functions to normalize the numerical data.

For illustration purpose, I will use tips data available in Seaborn.

For now let's scale those numerical features with Scikit-Learn preprocessing functions. We will use MinMaxScaler which scale the data to the range between 0 and 1 by default. If you want a different range, you can change that.

